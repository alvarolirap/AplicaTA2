{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deben instalar el modelo \"en_core_web_lg\"\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = natural language pipeline\n",
    "# Todos los documentos/palabras se transforman a ese objeto\n",
    "\n",
    "doc = nlp(u'the dog chases the cat')\n",
    "\n",
    "#Analizando el vector del documento, que tiene 300-dim\n",
    "print(doc.vector.shape)\n",
    "#Se calcular promediando los vectores de cada una de las palabras en el documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Análisis por cada token, que se contrasta con \"cat\"\n",
    "doc = nlp(u'the dog chases the cat')\n",
    "for token in doc:\n",
    "    print(token, token.similarity(nlp(u'cat')))\n",
    "\n",
    "#Se observa que \"dog\" es el término más cercano a \"cat\" (a mayor valor, mayor similitud)\n",
    "#Esto significa que ambos términos (dog, cat) tienden a aparecer en contextos similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"the cat sleeps\", \n",
    "        \"the dog plays\", \n",
    "        \"the dog chases the cat\"]\n",
    "\n",
    "#Ordenando los términos:\n",
    "vocabulary = sorted(list(set(\" \".join(corpus).split())))\n",
    "print(vocabulary)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot vectors (vocabulario ordenado)\n",
    "cat    = [1, 0, 0, 0, 0, 0]\n",
    "chases = [0, 1, 0, 0, 0, 0]\n",
    "dog    = [0, 0, 1, 0, 0, 0]\n",
    "plays  = [0, 0, 0, 1, 0, 0]\n",
    "sleeps = [0, 0, 0, 0, 1, 0]\n",
    "the    = [0, 0, 0, 0, 0, 1]\n",
    "\n",
    "#Esta representación también se puede generar automáticamente a partir del corpus (p.e. con \"gensim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Generamos las dos matrices para procesar los resultados\n",
    "#Arquitectura con una capa oculta de 3 dimensiones\n",
    "\n",
    "#W0 -> matriz de pesos entre el input y hidden layer\n",
    "W0 = np.random.rand(3,6)\n",
    "#W1 -> matriz de pesos entre el hidden y output layer\n",
    "W1 = np.random.rand(6,3)\n",
    "\n",
    "print(W0.shape)\n",
    "print(W0)\n",
    "print(W1.shape)\n",
    "print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos una prueba simple con el vector \"dog\"\n",
    "X = np.array(dog)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos el producto del vector \"dog\" con la matriz de pesos de la capa oculta\n",
    "Ht = (X).dot(W0.T)\n",
    "print(Ht)\n",
    "#\"Ht\" es la tercera \"columna\" de la matriz W0, y es debido a que \"dog\" tiene el índice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos el vector de la capa de salida (de tamaño del vocabulario)\n",
    "HtW1 = Ht.dot(W1.T)\n",
    "print(HtW1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función softmax de la capa de salida (output)\n",
    "import math\n",
    "def softmax(H):\n",
    "    sumatoria = sum([math.exp(w) for w in H])\n",
    "    return [math.exp(w)/sumatoria for w in H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos el vector de palabra objetivo, pasandolo por la funcion \"softmax\"\n",
    "y_pred = softmax(HtW1)\n",
    "#El vector \"y_pred\" es del tamaño del vocabulario (6)\n",
    "print(y_pred)\n",
    "#\"softmax\" convierte el vector \"y_pred\" a valores entre 0 y 1, y que sumen 1\n",
    "print(sum(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si el objetivo era \"plays\"\n",
    "y = np.array(plays)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se calcula la pérdida (loss)\n",
    "loss = y - softmax(y_pred)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asumiendo que ya se ajustaron los pesos:\n",
    "embedding_dog = (W0.T)[2]\n",
    "print(embedding_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otra forma: promediando las matrices de peso\n",
    "for i,token in enumerate(vocabulary):\n",
    "    print(token, \"\\t\", ((W0.T)[i] + W1[i])/2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
