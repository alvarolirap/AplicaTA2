{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deben instalar el modelo \"en_core_web_lg\"\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "#nlp = natural language pipeline\n",
    "# Todos los documentos/palabras se transforman a ese objeto\n",
    "\n",
    "doc = nlp(u'the dog chases the cat')\n",
    "\n",
    "#Analizando el vector del documento, que tiene 300-dim\n",
    "print(doc.vector.shape)\n",
    "#Se calcular promediando los vectores de cada una de las palabras en el documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0.23351583568976755\n",
      "dog 0.8016854370235484\n",
      "chases 0.2932192320096472\n",
      "the 0.23351583568976755\n",
      "cat 1.0\n"
     ]
    }
   ],
   "source": [
    "#Análisis por cada token, que se contrasta con \"cat\"\n",
    "doc = nlp(u'the dog chases the cat')\n",
    "for token in doc:\n",
    "    print(token, token.similarity(nlp(u'cat')))\n",
    "\n",
    "#Se observa que \"dog\" es el término más cercano a \"cat\" (a mayor valor, mayor similitud)\n",
    "#Esto significa que ambos términos (dog, cat) tienden a aparecer en contextos similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'chases', 'dog', 'plays', 'sleeps', 'the']\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"the cat sleeps\", \n",
    "        \"the dog plays\", \n",
    "        \"the dog chases the cat\"]\n",
    "\n",
    "#Ordenando los términos:\n",
    "vocabulary = sorted(list(set(\" \".join(corpus).split())))\n",
    "print(vocabulary)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot vectors (vocabulario ordenado)\n",
    "cat    = [1, 0, 0, 0, 0, 0]\n",
    "chases = [0, 1, 0, 0, 0, 0]\n",
    "dog    = [0, 0, 1, 0, 0, 0]\n",
    "plays  = [0, 0, 0, 1, 0, 0]\n",
    "sleeps = [0, 0, 0, 0, 1, 0]\n",
    "the    = [0, 0, 0, 0, 0, 1]\n",
    "\n",
    "#Esta representación también se puede generar automáticamente a partir del corpus (p.e. con \"gensim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6)\n",
      "[[0.578087   0.21055022 0.88069671 0.82253139 0.01330747 0.69976429]\n",
      " [0.78158133 0.94803501 0.387175   0.47130946 0.70111548 0.56435378]\n",
      " [0.50982234 0.15929935 0.49935534 0.46864689 0.88594132 0.01861806]]\n",
      "(6, 3)\n",
      "[[0.12916711 0.8402607  0.0686335 ]\n",
      " [0.49158885 0.78810514 0.16128096]\n",
      " [0.62747719 0.80128    0.06318016]\n",
      " [0.7623259  0.51650066 0.25898847]\n",
      " [0.80331432 0.76748241 0.84503197]\n",
      " [0.72317661 0.66501992 0.21586997]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Generamos las dos matrices para procesar los resultados\n",
    "#Arquitectura con una capa oculta de 3 dimensiones\n",
    "\n",
    "#W0 -> matriz de pesos entre el input y hidden layer\n",
    "W0 = np.random.rand(3,6)\n",
    "#W1 -> matriz de pesos entre el hidden y output layer\n",
    "W1 = np.random.rand(6,3)\n",
    "\n",
    "print(W0.shape)\n",
    "print(W0)\n",
    "print(W1.shape)\n",
    "print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Hacemos una prueba simple con el vector \"dog\"\n",
    "X = np.array(dog)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88069671 0.387175   0.49935534]\n"
     ]
    }
   ],
   "source": [
    "#Calculamos el producto del vector \"dog\" con la matriz de pesos de la capa oculta\n",
    "Ht = (X).dot(W0.T)\n",
    "print(Ht)\n",
    "#\"Ht\" es la tercera \"columna\" de la matriz W0, y es debido a que \"dog\" tiene el índice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47335749 0.8186118  0.89440203 1.00068133 1.4265975  1.00217417]\n"
     ]
    }
   ],
   "source": [
    "#Calculamos el vector de la capa de salida (de tamaño del vocabulario)\n",
    "HtW1 = Ht.dot(W1.T)\n",
    "print(HtW1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función softmax de la capa de salida (output)\n",
    "import math\n",
    "def softmax(H):\n",
    "    sumatoria = sum([math.exp(w) for w in H])\n",
    "    return [math.exp(w)/sumatoria for w in H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10079306934352682, 0.14235499618860578, 0.15356349623539362, 0.1707829478989697, 0.2614674006892399, 0.17103808964426417]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "#Calculamos el vector de palabra objetivo, pasandolo por la funcion \"softmax\"\n",
    "y_pred = softmax(HtW1)\n",
    "#El vector \"y_pred\" es del tamaño del vocabulario (6)\n",
    "print(y_pred)\n",
    "#\"softmax\" convierte el vector \"y_pred\" a valores entre 0 y 1, y que sumen 1\n",
    "print(sum(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Si el objetivo era \"plays\"\n",
    "y = np.array(plays)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15585559 -0.16246974 -0.16430103  0.8328453  -0.1830216  -0.16719735]\n"
     ]
    }
   ],
   "source": [
    "#Se calcula la pérdida (loss)\n",
    "loss = y - softmax(y_pred)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88069671 0.387175   0.49935534]\n"
     ]
    }
   ],
   "source": [
    "#Asumiendo que ya se ajustaron los pesos:\n",
    "embedding_dog = (W0.T)[2]\n",
    "print(embedding_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat \t [0.35362706 0.81092101 0.28922792]\n",
      "chases \t [0.35106954 0.86807007 0.16029015]\n",
      "dog \t [0.75408695 0.5942275  0.28126775]\n",
      "plays \t [0.79242865 0.49390506 0.36381768]\n",
      "sleeps \t [0.40831089 0.73429894 0.86548664]\n",
      "the \t [0.71147045 0.61468685 0.11724402]\n"
     ]
    }
   ],
   "source": [
    "#Otra forma: promediando las matrices de peso\n",
    "for i,token in enumerate(vocabulary):\n",
    "    print(token, \"\\t\", ((W0.T)[i] + W1[i])/2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
