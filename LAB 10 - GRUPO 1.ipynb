{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación de Librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando Anaconda Prompt se debe usar los siguientes comandos para importar la librería de Keras.\n",
    "<br>Link: https://medium.com/@pushkarmandot/installing-tensorflow-theano-and-keras-in-spyder-84de7eb0f0df\n",
    "<br>TensorFlow: https://www.tensorflow.org/install/\n",
    "\n",
    "```conda create -n tensorflow-gpu pip python=3.5```\n",
    "<br>```conda activate tensorflow-gpu```\n",
    "<br>```conda install keras ```\n",
    "\n",
    "Otra opción es la siguiente:\n",
    "<br>Entrar en modo administrador a Anaconda Prompt e introducir los siguientes comandos.\n",
    "<br>```conda update conda ```\n",
    "<br>```conda install keras ```\n",
    "\n",
    "Si está usando Linux, usar los siguientes comandos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cython\n",
      "  Downloading https://files.pythonhosted.org/packages/90/3e/8fb8aacc6eef05b2c80ff46f02c850d41ea01dc43eb539c45aa2b783b2d2/Cython-0.28.3-cp35-cp35m-win_amd64.whl (2.4MB)\n",
      "Installing collected packages: cython\n",
      "Successfully installed cython-0.28.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  The scripts cygdb.exe, cython.exe and cythonize.exe are installed in 'C:\\Users\\alirapal\\AppData\\Roaming\\Python\\Python35\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting regex==2017.04.5\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/66/e1c7a49068bc9fae46b3acb9b2c6f4cbb095c2e835c00de1ff12c82553ed/regex-2017.04.05-cp35-none-win_amd64.whl (243kB)\n",
      "Installing collected packages: regex\n",
      "Successfully installed regex-2017.4.5\n",
      "Collecting pathlib\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/aa/9b065a76b9af472437a0059f77e8f962fe350438b927cb80184c32f075eb/pathlib-1.0.1.tar.gz (49kB)\n",
      "Building wheels for collected packages: pathlib\n",
      "  Running setup.py bdist_wheel for pathlib: started\n",
      "  Running setup.py bdist_wheel for pathlib: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\alirapal\\AppData\\Local\\pip\\Cache\\wheels\\f9\\b2\\4a\\68efdfe5093638a9918bd1bb734af625526e849487200aa171\n",
      "Successfully built pathlib\n",
      "Installing collected packages: pathlib\n",
      "Successfully installed pathlib-1.0.1\n",
      "Collecting msgpack\n",
      "  Downloading https://files.pythonhosted.org/packages/9a/4f/7c1188ff64148b36d0d7ddeaba0f6e8e2fb7a46cd942f3543420b714a89f/msgpack-0.5.6-cp35-cp35m-win_amd64.whl (85kB)\n",
      "Installing collected packages: msgpack\n",
      "Successfully installed msgpack-0.5.6\n",
      "Collecting tensorflow-gpu\n",
      "  Downloading https://files.pythonhosted.org/packages/42/97/ce28b1651b59cafb6abd2d62df2856b6c139c8f3eb5a0f66ca41ca33ab92/tensorflow_gpu-1.8.0-cp35-cp35m-win_amd64.whl (88.9MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow-gpu) (1.14.5)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow-gpu) (0.31.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow-gpu) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow-gpu) (3.5.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow-gpu) (0.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow-gpu) (1.11.0)\n",
      "Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow-gpu) (1.8.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow-gpu) (0.6.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from protobuf>=3.4.0->tensorflow-gpu) (39.2.0)\n",
      "Requirement already satisfied: html5lib==0.9999999 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu) (0.9999999)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu) (0.14.1)\n",
      "Requirement already satisfied: bleach==1.5.0 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu) (1.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu) (2.6.11)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  The scripts freeze_graph.exe, saved_model_cli.exe, tensorboard.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\alirapal\\AppData\\Roaming\\Python\\Python35\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from keras) (1.14.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: h5py in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: keras_applications==1.0.2 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from keras) (1.0.2)\n",
      "Requirement already satisfied: keras_preprocessing==1.0.1 in c:\\users\\alirapal\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from keras) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install cython --user\n",
    "!pip install --force-reinstall regex==2017.04.5\n",
    "!pip install pathlib --user\n",
    "!pip install msgpack --user\n",
    "!pip install tensorflow-gpu --user\n",
    "!pip install keras --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadir en el path las librerias importadas si es que estás en Windows:\n",
    "\n",
    "``` set path=%PATH%;C:\\Users\\Alvaro\\AppData\\Roaming\\Python\\Python35\\Scripts ```\n",
    "\n",
    "Pruebo la correcta importación de librerías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alirapal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TF!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant(\"Hello, TF!\")\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "print(sess.run(a + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Archivo de texto \n",
    "DATA_DIR = \"./lotr.txt\" \n",
    "#Modificar BATCH_SIZE o HIDDEN_DIM en caso tengan problemas de memoria\n",
    "BATCH_SIZE = 50 \n",
    "HIDDEN_DIM = 250 #500\n",
    "#Parametro para longitud de secuencia a analizar\n",
    "SEQ_LENGTH = 50 \n",
    "#Parametro para cargar un pesos previamente entrenados (checkpoint)\n",
    "WEIGHTS = '' \n",
    "\n",
    "#Parametro para indicar cuantos caracteres generar en cada prueba\n",
    "GENERATE_LENGTH = 500 \n",
    "#Parametros para la red neuronal\n",
    "LAYER_NUM = 2 \n",
    "NB_EPOCH = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función A:\n",
    "<br>(1) Carga de un archivo de texto, (2) Construcción de estructuras de entrada y salida de la red**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for preparing the training data\n",
    "def load_data(data_dir, seq_length):\n",
    "    #Carga del archivo\n",
    "    data = open(data_dir, 'r').read()\n",
    "    #Caracteres unicos\n",
    "    chars = list(set(data))\n",
    "    VOCAB_SIZE = len(chars)\n",
    "\n",
    "    print('Data length: {} characters'.format(len(data)))\n",
    "    print('Vocabulary size: {} characters'.format(VOCAB_SIZE))\n",
    "    print(chars)\n",
    "    \n",
    "    #Indexacion de los caracteres\n",
    "    ix_to_char = {ix:char for ix, char in enumerate(chars)}\n",
    "    char_to_ix = {char:ix for ix, char in enumerate(chars)}\n",
    "    \n",
    "    #Estructuras de entrada y salida\n",
    "    NUMBER_OF_SEQ = int(len(data)/seq_length)\n",
    "    print('Number of sequences: {}'.format(NUMBER_OF_SEQ))\n",
    "    X = np.zeros((NUMBER_OF_SEQ, seq_length, VOCAB_SIZE))\n",
    "    y = np.zeros((NUMBER_OF_SEQ, seq_length, VOCAB_SIZE))\n",
    "    \n",
    "    for i in range(0, NUMBER_OF_SEQ):\n",
    "        #LLenado de la estructura de entrada X\n",
    "        X_sequence = data[i*seq_length:(i+1)*seq_length]\n",
    "        X_sequence_ix = [char_to_ix[value] for value in X_sequence]\n",
    "        #one-hot-vector (input)\n",
    "        input_sequence = np.zeros((seq_length, VOCAB_SIZE))  \n",
    "        #uso del diccionario para completar el one-hot-vector\n",
    "        for j in range(seq_length):\n",
    "            input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "            X[i] = input_sequence\n",
    "            \n",
    "        #Llenado de la estructura de salida y\n",
    "        y_sequence = data[i*seq_length+1:(i+1)*seq_length+1]\n",
    "        y_sequence_ix = [char_to_ix[value] for value in y_sequence]\n",
    "        #one-hot-vector (output)\n",
    "        target_sequence = np.zeros((seq_length, VOCAB_SIZE))\n",
    "        #uso del diccionario para completar el one-hot-vector\n",
    "        for j in range(seq_length):\n",
    "            target_sequence[j][y_sequence_ix[j]] = 1.\n",
    "            y[i] = target_sequence\n",
    "            \n",
    "    return X, y, VOCAB_SIZE, ix_to_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función B:\n",
    "<br>Generación de textos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for generating text\n",
    "def generate_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y Prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uso de la Función A: carga de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 3262172 characters\n",
      "Vocabulary size: 99 characters\n",
      "['S', '(', '\\n', '3', 'a', 'r', ':', 'B', 'e', '-', 'K', 'ó', 'k', '1', '«', 'm', '=', 'd', 'u', '}', '2', 'z', 'X', '8', 'N', 'g', '>', '—', '`', 'G', 'c', '9', 'w', 'T', 'l', '…', 'C', 'F', 'U', 'I', 'W', '4', '–', '»', '¤', '7', 'o', '*', 'b', '0', 'µ', '’', '#', 'y', '¢', '_', 'v', 'j', 'P', 'M', 'Z', '.', '‘', 'H', 'x', 'p', '6', '5', 'A', '!', ')', '\"', 'V', ' ', '<', 'D', '?', 'Q', '¥', '/', 'i', '‚', 'h', 'L', 'R', 'Y', ',', '®', '&', 'q', \"'\", 'J', 's', 'E', 'n', ';', 't', 'O', 'f']\n",
      "Number of sequences: 65243\n"
     ]
    }
   ],
   "source": [
    "# Creating training data\n",
    "X, y, VOCAB_SIZE, ix_to_char = load_data(DATA_DIR, SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Es importante guardar el diccionario `ix_to_char` en un archivo binario. Este debe ser cargado cada vez que se quiera retomar el entrenamiento o generar texto a partir de un checkpoint, debido a que el orden de los caracteres en el diccionario podría modificarse (no es un orden fijo)**\n",
    "<br>**NO MODIFICAR ESTE PICKLE AL REINICIAR EL NOTEBOOK PARA PROBAR CHECKPOINTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No modificar el pickle al reiniciar el cuaderno de trabajo para probar checkpoints previos\n",
    "with open('ix_to_char.pickle', 'wb') as handle:\n",
    "    pickle.dump(ix_to_char, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'S', 1: '(', 2: '\\n', 3: '3', 4: 'a', 5: 'r', 6: ':', 7: 'B', 8: 'e', 9: '-', 10: 'K', 11: 'ó', 12: 'k', 13: '1', 14: '«', 15: 'm', 16: '=', 17: 'd', 18: 'u', 19: '}', 20: '2', 21: 'z', 22: 'X', 23: '8', 24: 'N', 25: 'g', 26: '>', 27: '—', 28: '`', 29: 'G', 30: 'c', 31: '9', 32: 'w', 33: 'T', 34: 'l', 35: '…', 36: 'C', 37: 'F', 38: 'U', 39: 'I', 40: 'W', 41: '4', 42: '–', 43: '»', 44: '¤', 45: '7', 46: 'o', 47: '*', 48: 'b', 49: '0', 50: 'µ', 51: '’', 52: '#', 53: 'y', 54: '¢', 55: '_', 56: 'v', 57: 'j', 58: 'P', 59: 'M', 60: 'Z', 61: '.', 62: '‘', 63: 'H', 64: 'x', 65: 'p', 66: '6', 67: '5', 68: 'A', 69: '!', 70: ')', 71: '\"', 72: 'V', 73: ' ', 74: '<', 75: 'D', 76: '?', 77: 'Q', 78: '¥', 79: '/', 80: 'i', 81: '‚', 82: 'h', 83: 'L', 84: 'R', 85: 'Y', 86: ',', 87: '®', 88: '&', 89: 'q', 90: \"'\", 91: 'J', 92: 's', 93: 'E', 94: 'n', 95: ';', 96: 't', 97: 'O', 98: 'f'}\n"
     ]
    }
   ],
   "source": [
    "print(ix_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65243, 50, 99) (65243, 50, 99) 99\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de la RNN (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and compiling the Network\n",
    "model = Sequential()\n",
    "\n",
    "#Añadiendo las capas LSTM\n",
    "model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "for i in range(LAYER_NUM - 1):\n",
    "    model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "#Añadiendo la operacion de salida\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#\"Compilando\" = instanciando la RNN con su función de pérdida y optimización\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";Hn88bkkbrrrrWWWWC¥¥¥¥¥««RRR###\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "//////-----------HHHHHH––PPooWzzWWWWVVGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>>>&Ig\"\"\"\"\"‘WWVVWGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>>>&Ig\"\"\"\"\"‘WWVVWGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>>>&Ig\"\"\"\"\"‘WWVVWGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>>>&Ig\"\"\"\"\"‘WWVVWGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>>>&Ig\"\"\"\"\"‘WWVVWGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>>>&Ig\"\"\"\"\"‘WWVVWGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>"
     ]
    },
    {
     "data": {
      "text/plain": [
       "';Hn88bkkbrrrrWWWWC¥¥¥¥¥««RRR###\\n\\n\\n\\n\\n\\n//////-----------HHHHHH––PPooWzzWWWWVVGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>>>&Ig\"\"\"\"\"‘WWVVWGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>>>&Ig\"\"\"\"\"‘WWVVWGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>>>&Ig\"\"\"\"\"‘WWVVWGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>>>&Ig\"\"\"\"\"‘WWVVWGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>>>&Ig\"\"\"\"\"‘WWVVWGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>>>&Ig\"\"\"\"\"‘WWVVWGGGGGGGEEHHHSSM?????333333333333gIIggI«==‘MM‘>>>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate some sample before training to know how bad it is!\n",
    "generate_text(model, GENERATE_LENGTH, VOCAB_SIZE, ix_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se cargan los pesos (y el diccionario de los one-hot-vectors) en caso haya habido un entrenamiento previo**\n",
    "<br>WEIGHTS debe tener el valor del nombre del archivo de \"checkpoint\" guardado. Por ejemplo:\n",
    "<br>```WEIGHTS = \"checkpoint_layer_2_hidden_250_epoch_60.hdf5\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se cargan los pesos de un entrenamiento previo (si se desea restaurar una ejecucion)\n",
    "#Se calcula el numero de epocas en base al nombre del archivo\n",
    "#Se carga el diccionario de caracteres (one-hot-vectors) para la generacion\n",
    "if not WEIGHTS == '':\n",
    "    model.load_weights(WEIGHTS)\n",
    "    nb_epoch = int(WEIGHTS[WEIGHTS.rfind('_') + 1:WEIGHTS.find('.')])\n",
    "    with open('ix_to_char.pickle', 'rb') as handle:\n",
    "        ix_to_char = pickle.load(handle)\n",
    "else:\n",
    "    #Si se va a empezar de 0:\n",
    "    nb_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 0\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 445s 7ms/step - loss: 2.0676\n",
      "Z  the  hobbits  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  the  hills  and  th\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 466s 7ms/step - loss: 1.5330\n",
      "k  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  t\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 456s 7ms/step - loss: 1.4100\n",
      "‘  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  t\n",
      "\n",
      "Epoch: 3\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 445s 7ms/step - loss: 1.3514\n",
      "¥  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  the  stone  of  t\n",
      "\n",
      "Epoch: 4\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 448s 7ms/step - loss: 1.3149\n",
      "s  the  stones  of  the  trees  and  the  stone  of  the  trees  and  the  stone  of  the  trees  and  the  stone  of  the  trees  and  the  stone  of  the  trees  and  the  stone  of  the  trees  and  the  stone  of  the  trees  and  the  stone  of  the  trees  and  the  stone  of  the  trees  and  the  stone  of  the  trees  and  the  stone  of  the  trees  and  the  stone  of  the  trees  and  the  stone  of  the  trees  and  the  stone  of  the  trees  and  the  stone  of  the  trees  and  t\n",
      "\n",
      "Epoch: 5\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 425s 7ms/step - loss: 1.2887\n",
      "¢  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream  and  the  stream\n",
      "\n",
      "Epoch: 6\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 425s 7ms/step - loss: 1.2682\n",
      "‚  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the \n",
      "\n",
      "Epoch: 7\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 424s 6ms/step - loss: 1.2519\n",
      "; and the  stars were  still  the  strange  stone  of  the  strength  of  the  stream  that  had  been  the  strange  things  and  the  strange  things  that  we  have  seen  the  strange  things  and  the  strange  things  that  we  have  seen  the  strange  things  and  the  strange  things  that  we  have  seen  the  strange  things  and  the  strange  things  that  we  have  seen  the  strange  things  and  the  strange  things  that  we  have  seen  the  strange  things  and  the  strange  \n",
      "\n",
      "Epoch: 8\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 426s 7ms/step - loss: 1.2379\n",
      "y  had  been  all  the  store  of  the  dark  and  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of  the  shadows  of \n",
      "\n",
      "Epoch: 9\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 426s 7ms/step - loss: 1.2262\n",
      "d  the  shadow  of  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  \n",
      "\n",
      "Epoch: 10\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 424s 7ms/step - loss: 1.2156\n",
      "Company  was  still  still  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  of  the  stream  \n",
      "\n",
      "Epoch: 11\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 428s 7ms/step - loss: 1.2061\n",
      "The  sun  was  still  and  smoke  and  stone  and  stone  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood  and  stood\n",
      "\n",
      "Epoch: 12\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 426s 7ms/step - loss: 1.1976\n",
      "; but the  sun was  silent, and  then  an answer  that  they  were  already  been \n",
      "seen  and  shadows  and  stones  and  the  shadow  of  the  shadow  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  the  side  of  \n",
      "\n",
      "Epoch: 13\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 429s 7ms/step - loss: 1.1896\n",
      "Company  was  still  a  dark  shape  and  the  stone  that  had  been  set  out  on  the  stone  and  the  stone  that  had  been  set  out  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  started  and  star\n",
      "\n",
      "Epoch: 14\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 423s 6ms/step - loss: 1.1823\n",
      "7  the  dark  shapes  of  the  door  and  the  stones  and  the  dwarves  and  the  trees  and  the  dwarves  and  the  trees  and  the  dwarves  and  the  trees  and  the  dwarves  and  the  trees  and  the  dwarves  and  the  trees  and  the  dwarves  and  the  trees  and  the  dwarves  and  the  trees  and  the  dwarves  and  the  trees  and  the  dwarves  and  the  trees  and  the  dwarves  and  the  trees  and  the  dwarves  and  the  trees  and  the  dwarves  and  the  trees  and  the  dwa\n",
      "\n",
      "Epoch: 15\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 423s 6ms/step - loss: 1.1756\n",
      "ó  the  stream  that  had  been  seen  that  the  dwarves  had  been  the  strange  things  that  had  been  the  strength  of  the  dwarves  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  a\n",
      "\n",
      "Epoch: 16\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 420s 6ms/step - loss: 1.1691\n",
      "4(                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "\n",
      "Epoch: 17\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 425s 7ms/step - loss: 1.1630\n",
      "®rin with his hands on the \n",
      "brink of the stones. \n",
      "     'The  days of  the  Mountains  of  the  Mountains  of  the  Mountains  of  the  Mountains  of  the  Mountain  that  had  been  seen  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwa\n",
      "\n",
      "Epoch: 18\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 424s 6ms/step - loss: 1.1572\n",
      ", and the  stone  was  still  the  stone  was  still  the  stone  was  still  silent,  and  the  stone  was  still  a  long  cloak  of  stone  and  looked  at  the  stone  and  stood  at  the  top  of  the  stone  that  had  been  a  great  court  of  the  dwarves  and  the  strange  things  that  had  been  a  great  court  of  the  dwarves  and  the  strange  things  that  had  been  a  great  court  of  the  dwarves  and  the  strange  things  that  had  been  a  great  court  of  the  dwarve\n",
      "\n",
      "Epoch: 19\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 422s 6ms/step - loss: 1.1518\n",
      "Ugg slowly  and  the  sun  shone  like  a  stone  that  had  been  seen  to  start  all  the  sound  of  the  sound  of  the  sun  shone  and  standing  by  the  sun  shone  and  standing  by  the  sun  shone  and  standing  by  the  sun  shone  and  standing  by  the  sun  shone  and  standing  by  the  sun  shone  and  standing  by  the  sun  shone  and  standing  by  the  sun  shone  and  standing  by  the  sun  shone  and  standing  by  the  sun  shone  and  standing  by  the  sun  shone  an\n",
      "\n",
      "Epoch: 20\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 423s 6ms/step - loss: 1.1465\n",
      "zed the  hobbits  to  the  stone  and  stood  at  the  stone  and  stood  at  the  stone  and  stood  and  shook  the  rocks  and  his  head  was  still  as  he  said  that  the  dwarves  had  been  a  great  company  of  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves\n",
      "\n",
      "Epoch: 21\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 419s 6ms/step - loss: 1.1415\n",
      "}  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the\n",
      "\n",
      "Epoch: 22\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 422s 6ms/step - loss: 1.1370\n",
      "µ  a  bit  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound \n",
      "\n",
      "Epoch: 23\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 423s 6ms/step - loss: 1.1324\n",
      "X  the  shadow  of  the  doors  of  the  doorstep  of  the  Mountain  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dw\n",
      "\n",
      "Epoch: 24\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 423s 6ms/step - loss: 1.1280\n",
      "xpect  to  see  the  sound  of  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves\n",
      "\n",
      "Epoch: 25\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 423s 6ms/step - loss: 1.1240\n",
      "he  straight  and  shouting.  They  were  still  singing  and  the  sound  of  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the\n",
      "\n",
      "Epoch: 26\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 422s 6ms/step - loss: 1.1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e  the  strangers  saw  them  all  the  strange  thing  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the\n",
      "\n",
      "Epoch: 27\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.1163\n",
      "‚d  the  stranger  of  the  stream  that  had  been  seen  they  had  been  seen  the  sun  was  still  seen  of  the  songs  of  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwar\n",
      "\n",
      "Epoch: 28\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.1125\n",
      "ve  had  a  power  of  the  strength  of  the  dark  and  the  stream  of  the  Mountain,  and  the  trees  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  of  the  dark  shapes  o\n",
      "\n",
      "Epoch: 29\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.1091\n",
      "Do not be seen. \n",
      "     'I will  not  say  that  they  will  be  so  small  and  thinking  of  the  dwarves  and  the  dwarves  and  the  dwarves  had  been  a  good  deal  of  the  dwarves  and  the  dwarves  and  the  dwarves  had  been  a  good  deal  of  the  dwarves  and  the  dwarves  and  the  dwarves  had  been  a  good  deal  of  the  dwarves  and  the  dwarves  and  the  dwarves  had  been  a  good  deal  of  the  dwarves  and  the  dwarves  and  the  dwarves  had  been  a  good  deal  o\n",
      "\n",
      "Epoch: 30\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 422s 6ms/step - loss: 1.1057\n",
      "ve  had  a  plan  on  the  stream,  and  they  were  still  silent  below  them  all  the  stream  below  them  all  the  stream  below  them  all  the  stream  below  them  all  the  stream  below  them  all  the  stream  below  them  all  the  stream  below  them  all  the  stream  below  them  all  the  stream  below  them  all  the  stream  below  them  all  the  stream  below  them  all  the  stream  below  them  all  the  stream  below  them  all  the  stream  below  them  all  the  stream\n",
      "\n",
      "Epoch: 31\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 420s 6ms/step - loss: 1.1027\n",
      ":  'What  about  the \n",
      "words  of  the  Mountain  in  the  dark  things  that  have  not  had  no  time  to  see  the  time  they  were  a  good  deal  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  \n",
      "\n",
      "Epoch: 32\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.0994\n",
      "He  saw  the  stars  and  the  stream  to  the  stone  the  dwarves  and  the  stream  went  on  to  the  stone  the  stars.  The  dwarves  had  been  seen  the  dwarves  and  the  stream  went  on  to  the  stone  the  stars.  The  dwarves  had  been  seen  the  dwarves  and  the  stream  went  on  to  the  stone  the  stars.  The  dwarves  had  been  seen  the  dwarves  and  the  stream  went  on  to  the  stone  the  stars.  The  dwarves  had  been  seen  the  dwarves  and  the  stream  went \n",
      "\n",
      "Epoch: 33\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.0965\n",
      "®ril \n",
      "were  still  the  sound  of  the  dwarves  and  the  little  shadow  of  the  river  and  the  shadow  of  the  river  and  the  shadow  of  the  river  and  the  shadow  of  the  river  and  the  shadow  of  the  river  and  the  shadow  of  the  river  and  the  shadow  of  the  river  and  the  shadow  of  the  river  and  the  shadow  of  the  river  and  the  shadow  of  the  river  and  the  shadow  of  the  river  and  the  shadow  of  the  river  and  the  shadow  of  the  river  a\n",
      "\n",
      "Epoch: 34\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.0938\n",
      "##-     'I  will  go  to  the  best  of  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the\n",
      "\n",
      "Epoch: 35\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.0909\n",
      "9     'I don't know what they were all about the  days of the  Ring and  the  days of  the  Ring  and \n",
      "the  days of the  Ring  where the  Ring  would  be \n",
      "carried out of the walls of the City. \n",
      "     'There  are  more  than  the  dwarves  and  the  dwarves  had  been  a  great  deal  of  the  dwarves  and  the  strange  table  was  a  great  deal  of  the  dwarves  and  the  stream  that  had  been  a  great  deal  of  the  dwarves  and  the  strange  table  was  a  great  deal  of  the  dwarves \n",
      "\n",
      "Epoch: 36\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 423s 6ms/step - loss: 1.0881\n",
      "and  the  spiders  that  was  a  great  commanding  path  that  they  were  a  good  deal  of  the  dwarves  of  the  Mountain,  and  the  dwarves  had  stopped  as  if  they  could  see  no  longer  any  time  to  see  the  trees  and  the  dwarves  had  been  a  good  deal  of  the  dwarves  of  the  Mountain,  and  the  dwarves  had  stopped  as  if  they  could  see  no  longer  any  time  to  see  the  trees  and  the  dwarves  had  been  a  good  deal  of  the  dwarves  of  the  Mountain, \n",
      "\n",
      "Epoch: 37\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 422s 6ms/step - loss: 1.0857\n",
      "Company  will  be  seen  for  the  same  time  that  had  been  a  strange  thing,  and  the  dwarves  and  the  land  of  the  Mountain,  and  the  dwarves  had  been  in  the  dark  the  dwarves  and  the  land  of  the  Mountain,  and  the  dwarves  had  been  in  the  dark  the  dwarves  and  the  land  of  the  Mountain,  and  the  dwarves  had  been  in  the  dark  the  dwarves  and  the  land  of  the  Mountain,  and  the  dwarves  had  been  in  the  dark  the  dwarves  and  the  land  o\n",
      "\n",
      "Epoch: 38\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 423s 6ms/step - loss: 1.0833\n",
      "? ' \n",
      "     'I  do not know,' said Gandalf.  \n",
      "     'The  man of Gondor  and  the  strangers  and  the \n",
      "strength of the  first  they had  been  seen  that  the  sun  was  singing  to  the  doors  of  the  Mountain,  and  the  dwarves  had  seen  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarv\n",
      "\n",
      "Epoch: 39\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.0809\n",
      "nd  the  strangers  and  the  sound  of  the  dwarves  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and  the  rocks  and\n",
      "\n",
      "Epoch: 40\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 420s 6ms/step - loss: 1.0787\n",
      "g  the  stone  and  the  trees  and  the  dwarves  and  the  light  of  the  dwarves  and  the  little  stone  they  could  not  get  on  the  ground.  \"The  dwarves  are  a  great  grey  smoke-messes  and  the  dwarves  and  the  little  stone  they  could  not  get  on  the  ground.  \"The  dwarves  are  a  great  grey  smoke-messes  and  the  dwarves  and  the  little  stone  they  could  not  get  on  the  ground.  \"The  dwarves  are  a  great  grey  smoke-messes  and  the  dwarves  and  the \n",
      "\n",
      "Epoch: 41\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.0766\n",
      "\" \n",
      "\"If we  can  help  you  and  the  door  of  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  and  the  dwarves  an\n",
      "\n",
      "Epoch: 42\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 423s 6ms/step - loss: 1.0744\n",
      "/h4> <br> \n",
      "\n",
      "The Crocuk Iminas, and if you don't. \n",
      "     'I do not know what  I  have  seen  any  more  than  a  \n",
      "stranger  of  the  dwarves  and  the  dwarves  had  been  a  great  commotion  of  the  dwarves  and  the  sound  of  the  dwarves  had  been  a  deal  of  the  dwarves  had  been  a  great  commotion  of  the  dwarves  and  the  sound  of  the  dwarves  had  been  a  deal  of  the  dwarves  had  been  a  great  commotion  of  the  dwarves  and  the  sound  of  the  dwarves  had  been \n",
      "\n",
      "Epoch: 43\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 422s 6ms/step - loss: 1.0724\n",
      "(and the \n",
      "stream  they  had  all  the  track  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  the  dwarves  of  \n",
      "\n",
      "Epoch: 44\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.0702\n",
      "\" \n",
      "\"It was  not  a  mighty  size  of  the  mountains.  They  were  still  spread  in  the  dark  they  could  not  get  out  of  the  stream.  There  was  a  silence  of  the  stream.  The  dwarves  had  seen  the  dwarves  and  Bilbo  was  sitting  and  strong  and  closed  and  strode  forward  and  standing  before  them.  They  had  a  strange  stream  that  had  been  seen  that  the  dwarves  had  seen  the  dwarves  and  Bilbo  was  sitting  and  strong  and  closed  and  strode  forward \n",
      "\n",
      "Epoch: 45\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 422s 6ms/step - loss: 1.0685\n",
      "he  stronger  \n",
      "stream through  the  walls of the  Mountains  of  the \n",
      "Mountains and the stones of the Mountains, and the stones were still spring out of the shadow of the stream. \n",
      "     The  sun was  shining  and  strongered  and  strong  and  clear  and  clear  throbbing  and  starlight  and  black  shapes,  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and\n",
      "\n",
      "Epoch: 46\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.0666\n",
      "Ring \n",
      "to  the  barrow-light.  The  sun  was  sinking  in  the  dark  water  and  the  sound  of  the  dwarves  and  the  great  stone  was  sinking  on  the  tree-trunk  and  smoke  and  stood  at  the  road  to  the  edge  of  the  house  of  the  trees  and  the  dwarves  had  been  in  the  dark  stone  of  the  dwarves  and  the  dwarves  had  been  in  the  dark  stone  of  the  dwarves  and  the  dwarves  had  been  in  the  dark  stone  of  the  dwarves  and  the  dwarves  had  been  in  \n",
      "\n",
      "Epoch: 47\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 420s 6ms/step - loss: 1.0648\n",
      "» King of the Marshes \n",
      "\n",
      " \n",
      " \n",
      "     The  sun was  set  on  the  stone  and  the  sound  of  the  dwarves  had  been  in  the  same  that  he  had  always  had  a  long  road  that  he  had  a  plan  of  the  dwarves  had  been  seen  for  the  secret  path  that  the  dwarves  had  seen  the  dwarves  had  been  seen  for  the  secret  path  that  the  dwarves  had  seen  the  dwarves  had  been  seen  for  the  secret  path  that  the  dwarves  had  seen  the  dwarves  had  been  seen  for  the  s\n",
      "\n",
      "Epoch: 48\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.0631\n",
      "xpected to  see  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  trees  and  the  tr\n",
      "\n",
      "Epoch: 49\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.0616\n",
      "7  and  the  dwarves  and  the  dwarves  of  the  dwarves  and  the  dwarves  of  the  dwarves  and  the  dwarves  of  the  dwarves  and  the  dwarves  of  the  dwarves  and  the  dwarves  of  the  dwarves  and  the  dwarves  of  the  dwarves  and  the  dwarves  of  the  dwarves  and  the  dwarves  of  the  dwarves  and  the  dwarves  of  the  dwarves  and  the  dwarves  of  the  dwarves  and  the  dwarves  of  the  dwarves  and  the  dwarves  of  the  dwarves  and  the  dwarves  of  the  dwarve\n",
      "\n",
      "Epoch: 50\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 423s 6ms/step - loss: 1.0599\n",
      "He  came  to  the  top  of  the  door  to  the  stone  and  the  stone  the  storm  of  the  dwarves  and  the  stream  took  the  hobbit's  face  and  stood  a  story  of  some  criff.  \"The  dwarves  are  seldom  to  the  dwarves  of  the  dwarves  and  the  dwarves  of  the  Mountain.  The  dwarves  had  set  his  head  and  stamped  by  the  trees  and  the  sound  of  the  dwarves  and  the  dwarves  of  the  Mountain.  The  dwarves  had  set  his  head  and  stamped  by  the  trees  and  t\n",
      "\n",
      "Epoch: 51\n",
      "\n",
      "Epoch 1/1\n",
      "65243/65243 [==============================] - 421s 6ms/step - loss: 1.0584\n",
      "QVUJ(JoUUa): \n",
      "     Chapter in the Wild  Mathor  had  been  seen  for  the  dwarves  and  the  dwarves  and  Bilbo  and  his  brother  to  the  door  that  he  had  a  little  silver  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  and  the  sound  of  the  dwarves  an\n",
      "\n",
      "Epoch: 52\n",
      "\n",
      "Epoch 1/1\n",
      "11750/65243 [====>.........................] - ETA: 6:03 - loss: 1.0366"
     ]
    }
   ],
   "source": [
    "# Training if there is no trained weights specified\n",
    "\n",
    "#Esta es la iteración importante\n",
    "#Pueden cambiar la condición para que termine en un determinado numero de epochs.\n",
    "while True:\n",
    "    print('\\n\\nEpoch: {}\\n'.format(nb_epoch))\n",
    "    #Ajuste del modelo, y entrenamiento de 1 epoca\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, verbose=1, epochs=1)\n",
    "    nb_epoch += 1\n",
    "    #Generacion de un texto al final de la epoca\n",
    "    generate_text(model, GENERATE_LENGTH, VOCAB_SIZE, ix_to_char)\n",
    "    #Pueden modificar esto para tener más checkpoints\n",
    "    if nb_epoch % 10 == 0:\n",
    "        model.save_weights('checkpoint_layer_{}_hidden_{}_epoch_{}.hdf5'.format(LAYER_NUM, HIDDEN_DIM, nb_epoch))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de texto\n",
    "Si instancian el modelo y sus parametros (ejecutando algunas celdas preliminares), y tienen los 2 archivos requeridos (.pickle y .hdf5) pueden generar el texto. \n",
    "<br>En el ejemplo de LOTR: `VOCAB_SIZE = 84` (si desean probarlo, se adjuntar los pesos y el diccionario, pero no el texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u(ROFoPZFSZ'PR"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "85",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-3038684d4d67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Loading the trained weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWEIGHTS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgenerate_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGENERATE_LENGTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mix_to_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-659268d180ae>\u001b[0m in \u001b[0;36mgenerate_text\u001b[1;34m(model, length, vocab_size, ix_to_char)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mix_to_char\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0my_char\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mix_to_char\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 85"
     ]
    }
   ],
   "source": [
    "#Cuidar de no reemplazar el pickle original\n",
    "with open('ix_to_char.pickle', 'rb') as handle:\n",
    "    ix_to_char = pickle.load(handle)\n",
    "    \n",
    "WEIGHTS = \"checkpoint_layer_2_hidden_250_epoch_50.hdf5\"\n",
    "# Loading the trained weights\n",
    "model.load_weights(WEIGHTS)\n",
    "generate_text(model, GENERATE_LENGTH, VOCAB_SIZE, ix_to_char)\n",
    "print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
